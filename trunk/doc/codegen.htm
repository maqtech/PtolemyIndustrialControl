<!-- $Id$ -->
<html>
<head>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<title>Code Generation</title>
<link href="default.css" rel="stylesheet" type="text/css">
</head>
<body>
<h1>Code Generation</h1>
<p>
Ptolemy II includes the very beginnings a code generation framework.
Currently, there are two levels of code generation, shallow and deep.
Shallow code generation converts a model that has been specified in
MoML (typically using Vergil) into a Java class definition.  This class
definition can be used in an applet, which results in faster download
times because less of the Ptolemy II infrastructure is required
to execute it. Shallow code generation uses components built into
the Ptolemy II tree.  Eventually, the process of creating an applet,
include packaging the requisite code in a jar file, will be more
automated.
<p>
Deep code generation parses the component definitions (which are
written in Java), and produces optimized code that does not require
code from the Ptolemy II tree.  Currently, this only works for some
models, and only in the SDF domain.  Also, the code generation process,
as currently implemented, requires vast amounts of memory, and thus
may not work at all on memory-limited platforms.
<p>
The implementation here should be viewed as highly preliminary.
<font color="red">It is likely to fail on all but a few simple test
cases.</font>  It is at the stage of being a concept demonstration
only.  We expect it to mature considerably in the near future.
<p>
Deep code generation parses Java component definitions, and provides
an API for accessing the abstract syntax tree.  It is possible,
in principle, to generate implementations in languages other than
Java from this AST.  Thus, we hope that in the future, we will have
code generators that produce C code for embedded processors,
or VHDL code for hardware design.
<p>
In 2000, Jeff Tsay created an initial implementation of Deep code
generation as part of his  his Masters project:
Jeff Tsay, "<a href="http://ptolemy.eecs.berkeley.edu/publications/papers/00/codegen/" target="_top">A Code Generation Framework for Ptolemy II</a>," ERL Technical Report UCB/ERL No. M00/25, Dept. EECS, University of California, Berkeley, CA  94720, May 19, 2000.

 <p>There is a shorter summary of Jeff's work at:
 <p>Jeff Tsay, Christopher Hylands and Edward Lee, 
<a href="http://ptolemy.eecs.berkeley.edu/publications/papers/00/javacodegen">"A Code Generation Framework for Java Component-Based Designs,"</a>
 CASES 00, November 17-19, 2000, San Jose, CA.

 <p>Jeff's work was a prototype of how we could do code generation in a
different manner, described in the above references and below.
Unfortunately, his prototype code was not easy to extend to match
changes in the Ptolemy type system.  More specfically, the type system
is Yuhong Xiong's area of research, and Jeff's work was not easy to
extend to deal with ArrayTokens.

<h2>Ptolemy Classic code generation</h2>

In Ptolemy Classic code generation, each separate platform had a
separate domain. This was a slight misuse of the domain
concept, since all most all of the separate platforms really had SDF
semantics, and each separate platform was really a target for the SDF
domain.  However, because of assumptions in the Ptolemy Classic
software architecture, it was easier to add new code generation
targets as separate domains.

 <p>In Ptolemy Classic, if you wanted to generate code for a new
processor, you had to create a new domain and then populate the domain
with new basic blocks that contained codeblocks of code that were
generated when the basic block was used.  This is a bit of a
simplification, but basically it meant that for each new processor,
the author had to generate a new Ramp basic block, a new Add basic
block etc.  This was very time consuming, and tended to have problems,
since if a bug was fixed in one Ramp actor, the bug needed to be fixed
in other Ramp actors in each domain.

The Adaptive Computing System (ACS) domain was an effort to work
around this issue, where the interface to each actor was shared
between multiple implementations.  This helped make it easier to
switch between different target implementations, since the ACS Ramp
actor always had the same interface, whereas if there were two Ramp
actors in two separate domains, then they might have different port
names, which made switching between the domains difficult.

 <p>More information about the ACS domain can be found in
E. K. Pauer, C. S. Myers, P. D. Fiore, J. M. Smith, C. M. Crawford, E. A. Lee, J. Lundblad and C. Hylands,
<a href="http://ptolemy.eecs.berkeley.edu/publications/papers/98/ACSmapping/">Algorithm Analysis and Mapping Environment for Adaptive Computing Systems,"</a>
 Presented at the Second Annual Workshop on High Performance
 Embedded Computing, MIT Labs, Lexington, MA, September, 1998. 

 <p>The ACS domain is part of Ptolemy 0.7.2devel, see
<a href="http://ptolemy.eecs.berkeley.edu/ptolemyclassic/pt0.7.2/"><CODE>http://ptolemy.eecs.berkeley.edu/ptolemyclassic/pt0.7.2/</CODE></a>


The Ptolemy Classic style of code generation was used to customize
different actors to take advantage of different features of a
processor.  For example, the Motorola 56x FIR filter actor would pick
a different codeblock depending on how the FIR filter was configured.

 <p>However, the downside of this approach is that the inter-actor
communication tended to consume quite a bit of time, so even with
really great actor implementations, we were getting performance hits
when data was passed between these actors.  It seems to us that
looking at the whole model would yield further performance
improvements.


<h2>Deep Code Generation</h2>

 <p>The Ptolemy II code generation system parses Ptolemy II actor
code, generates an Abstract Syntax Tree (AST), optimizes the tree
using standard and custom compiler optimization techniques and then
generates .class files that use very few of the Ptolemy II java
classes .  This approach is different from the Ptolemy Classic code
generation approach, where each actor contains target specific code.


 <p>Currently, in Ptolemy II, it is not possible to generate custom code 
using a codeblock.


<h2><a name="soot">Soot</a></h2>
Another approach we are trying is to use Soot, which is a 
Java optimization framework that we hope will have a better AST.

 <p>Currently, Steve Neuendorffer is developing a code generation system
using Soot.  Professor Shuvra S. Bhattacharyya of the University of Maryland
is working on C code generation using Soot.


<menu>
<li> <a href="http://www.sable.mcgill.ca/soot/" target="_top"><CODE>http://www.sable.mcgill.ca/soot/</CODE></a> 
</menu>

<p>Soot operates on class files by applying a series of transformations
that usually do compiler things like common subexpression elimination
or loop unrolling.  We can add transformations that do things like
flattening a model into one class for shallow code generation, or
further processing the AST for deep code generation.

<p>The advantage of Soot over Jeff Tsay's work is that by using soot, we
do not have to parse java files, and the name resolution of objects is
done.  In Jeff's code, we spent a lot of time trying to figure out the
fully dot qualified name of an object who's base name was 'String'.

<p>Jeff Tsay's work was a proof of concept demonstration on what
could be done.  We hope that by using Soot, we can generate a stable system
for use in a production environment.


<h3><a name="disassemblers">Disassemblers</a></h3>
Soot works with byte codes.  A Java decompiler or disassembler 
can help with debugging
<dl>
<dt> <CODE>jode</CODE>
<dd> <a href="http://jode.sourceforge.net/download.php" target="_top">http://jode.sourceforge.net/download.php</a> - Written in Java, but full GPL, so we can't distribute it.

<dt> <CODE>javap</CODE>
<dd> <a href="http://java.sun.com/j2se/1.3/docs/tooldocs/solaris/javap.html" target="_top"><CODE>http://java.sun.com/j2se/1.3/docs/tooldocs/solaris/javap.html</CODE></a> - Shipped with Sun's JDK.

<dt> <code>Source Again</code>
<dd> <a href="http://www.ahpah.com/sourceagain/" target="_top"><code>http://www.ahpah.com/sourceagain/</code></a> - Commercial product

<dt> <code>WingDis</code>
<dd> <a href="http://www.wingsoft.com/wingdis.html" target="_top"><code>http://www.wingsoft.com/wingdis.html</code></a> - Commercial product

<dt> <CODE>jad</CODE>
<dd> <a href="http://www.geocities.com/SiliconValley/Bridge/8617/jad.html" target="_top"><CODE>http://www.geocities.com/SiliconValley/Bridge/8617/jad.html</CODE></a> - Jad home page - used to have binaries only, but now broken.
<br><a href="http://www.geocities.com/zz_xu/jad.html#download" target="_top"><code>http://www.geocities.com/zz_xu/jad.html#download</code></a> - Mirror site from 1999 - Jad 1.5.7
<br><a href="http://www.jproof.com/faq/MoreInfo.html" target="_top">http://www.jproof.com/faq/MoreInfo.html</a> - Jad 1.5.7

<a href="http://www.meurrens.org/ip-Links/Java/codeEngineering/jad15.html" target="_top">Mirror, though downloads do not work</a>

</dl>

Other possibilities:
<menu>
<li> <a href="http://bcel.sourceforge.net/" target="_top"><CODE>http://bcel.sourceforge.net/</CODE></a>
</menu>


<h2>The code generator user interface</h2>
Christopher Hylands and Professor Edward A. Lee developed a user
interface to control code generation.  


<h2>Multiprocessors and DSP targets</h2>

Partitioning a model between multiple processors is fairly tricky, and
was a large area of research in Ptolemy Classic.  Only models with a
high degree of parallelism are amenable to running on multiple
processors.  Simply assigning each actor to a processor is not likely
to yield performance improvements, since the inter-actor communication
will really bog things down, especially on a high latency system like
a switched ethernet network.

 <p>Java can take advantage of multiple processors, so in theory, if
we use the process domains in Ptolemy II without code generation on a
multi processor machine, we should see that each Java thread will be
run on a separate processor.  However we have not done much work in
this area.  We'd like to see someone take the PN domain and work on
running it on multiple processors and seeing what sort of improvements
can be made.

 <p>In theory, once we have deep code generation, and we are creating
an AST and generating .class files, we can generate code for any
processor by either writing a new back end, or using a native Java
compiler like gcj.

<h2>Java To C converters</h2>
<dl>
<dl>
<dt> Java Coffee Break Decompiler links
<dd> <a href="http://www.javacoffeebreak.com/directory/index(32).html" target="_top"><CODE>http://www.javacoffeebreak.com/directory/index(32).html</CODE></a>
</dl>

<dt> GCJ - The GNU Compiler for Java
<dd> <a href="http://gcc.gnu.org/java/" target="_top"><CODE>http://gcc.gnu.org/java/</CODE></a>: JDK1.2 compliant
<BLOCKQUOTE>
<menu>
<li> Java source code directly to native machine code, 
<li> Java source code to Java bytecode (class files), 
<li>  and Java bytecode to native machine code. 
</menu>
</BLOCKQUOTE>


<dt> Jolt: Converting bytecode to C
<dd> <a href="http://www.meurrens.org/ip-Links/Java/codeEngineering/blackDown/jolt.html" target="_top"><CODE>http://www.meurrens.org/ip-Links/Java/codeEngineering/blackDown/jolt.html</CODE></a>: initial hack


<dt> Harissa
<dd> <a href="http://www.irisa.fr/compose/harissa/harissa.html" target="_top"><CODE>http://www.irisa.fr/compose/harissa/harissa.html</CODE></a>: 1999: JDK1.0.2?


<dt> Toba: A Java-to-C Translater
<dd> <a href="http://www.cs.arizona.edu/sumatra/toba/" target="_top"><CODE>http://www.cs.arizona.edu/sumatra/toba/</CODE></a>: Does not support JDK1.2

<dt> JCC
<dd> <a href="http://www.geocities.com/CapeCanaveral/Hangar/4040/jcc.html" target="_top"><CODE>http://www.geocities.com/CapeCanaveral/Hangar/4040/jcc.html</CODE></a>: 1997, probably does not support JDK1.2


</dl>

<h2>Misc</h2>
<menu>
<li> <a href="http://found.cs.nyu.edu/meyer/jasmin/">Jasmin</a> 
a Java Assembler Interface (1997)
<li> <a
href="http://www.geocrawler.com/archives/3/338/1996/8/0/1876595/">Jasmin
emacs mode</a>
</menu>
</body>
</html>

